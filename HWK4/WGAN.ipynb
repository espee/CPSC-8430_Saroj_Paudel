{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb9a7346-68fe-47e3-a8ca-1c0331d7c5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from pytorch_gan_metrics import get_inception_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "114504c5-b38f-4308-88d7-4c8fa61e3038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR10 dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def create_CIFAR10_dataloaders(batch_size): \n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(), \n",
    "        torchvision.transforms.Resize(32), \n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_CIFAR10_set = torchvision.datasets.CIFAR10(root='./cifar10/', train=True, download=True, transform=transform)\n",
    "    test_CIFAR10_set = torchvision.datasets.CIFAR10(root='./cifar10/', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_CIFAR10_dataloader = DataLoader(train_CIFAR10_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_CIFAR10_dataloader = DataLoader(test_CIFAR10_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_CIFAR10_dataloader, test_CIFAR10_dataloader\n",
    "\n",
    "print(\"Downloading CIFAR10 dataset...\")\n",
    "batch_size = 32\n",
    "train_dataloader, test_dataloader = create_CIFAR10_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1098d6c8-569d-40e0-8a82-170363f9bbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing generator and Discriminator (WGAN)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WGAN_Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=512, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (4): Linear(in_features=256, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WGAN_Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WGAN_Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(100,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.BatchNorm1d(256, 0.8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256,512),\n",
    "            nn.BatchNorm1d(512, 0.8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512,1024),\n",
    "            nn.BatchNorm1d(1024, 0.8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 3*32*32),\n",
    "            nn.Tanh()   \n",
    "        )\n",
    "    def forward(self, z):\n",
    "        x = self.net(z)\n",
    "        x = x.view(x.shape[0], *(3,32,32))\n",
    "        return x\n",
    "\n",
    "class WGAN_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WGAN_Discriminator, self).__init__()\n",
    "        self.model= nn.Sequential(\n",
    "            nn.Linear(3*32*32, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256,1),\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        validity = self.model(x)\n",
    "        return validity\n",
    "\n",
    "print(\"Initializing generator and Discriminator (WGAN)...\")\n",
    "wgan_generator = WGAN_Generator()\n",
    "wgan_discriminator = WGAN_Discriminator()\n",
    "wgan_generator.to(device)\n",
    "wgan_discriminator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9827d067-7195-438c-949f-ffa4a90a5742",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=5e-4\n",
    "epochs=50\n",
    "batch_size=32\n",
    "\n",
    "weight_clip = 0.01\n",
    "nCritic = 4\n",
    "\n",
    "def train(generator, discriminator, train_dataloader):\n",
    "\n",
    "    optim_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "    if not os.path.exists('train_generated_images_wgan/'): \n",
    "        os.makedirs('train_generated_images_wgan')\n",
    "        \n",
    "    inception_score_file = open(\"IS_wgan.csv\", \"w\")\n",
    "    inception_score_file.write('epoch, IS \\n')\n",
    "    \n",
    "    for epoch in range(epochs): \n",
    "        for i, (images, _) in enumerate(train_dataloader):\n",
    "\n",
    "            real_images = Variable(images.type(torch.cuda.FloatTensor))\n",
    "\n",
    "            ### train discriminator\n",
    "            optim_discriminator.zero_grad()\n",
    "            z = Variable(torch.Tensor(np.random.normal(0, 1, (images.shape[0], 100)))).to(device)\n",
    "            fake_images = generator(z).detach()\n",
    "            disc_loss = -torch.mean(discriminator(real_images)) + torch.mean(discriminator(fake_images))\n",
    "            disc_loss.backward()\n",
    "            optim_discriminator.step()\n",
    "\n",
    "            # apply weight clipping\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-weight_clip, weight_clip)\n",
    "\n",
    "            # Train generator every nCritic batch\n",
    "            if i % nCritic == 0:\n",
    "                optim_generator.zero_grad()\n",
    "                fake_images = generator(z)\n",
    "                gen_loss = -torch.mean(discriminator(fake_images))\n",
    "                gen_loss.backward()\n",
    "                optim_generator.step()\n",
    "            \n",
    "         # compute inception score and samples every epoch\n",
    "        z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (images.shape[0], 100)))).to(device)\n",
    "        samples = generator(z)\n",
    "\n",
    "        # normalize to [0, 1]\n",
    "        samples = samples.add(1.0).mul(0.5)\n",
    "        \n",
    "        assert 0 <= samples.min() and samples.max() <= 1\n",
    "        IS, IS_std = get_inception_score(samples)\n",
    "        print(\"epoch: \" + str(epoch) + ', inception score: ' + str(round(IS, 3)))\n",
    "\n",
    "        # samples = samples[:10].data.cpu()\n",
    "        # grid = utils.make_grid(samples, nrow = 5)\n",
    "        # utils.save_image(grid, 'train_generated_images_dcgan/epoch_{}.png'.format(str(epoch)))\n",
    "        \n",
    "        inception_score_file.write(str(epoch) + ', ' + str(round(IS, 3)) + '\\n')\n",
    "\n",
    "    inception_score_file.close()\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73d3c269-d513-499d-8dee-b6de76abaadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING WGAN MODEL...\n",
      "epoch: 0, inception score: 1.663\n",
      "epoch: 1, inception score: 1.577\n",
      "epoch: 2, inception score: 1.726\n",
      "epoch: 3, inception score: 1.595\n",
      "epoch: 4, inception score: 1.543\n",
      "epoch: 5, inception score: 1.707\n",
      "epoch: 6, inception score: 1.529\n",
      "epoch: 7, inception score: 1.739\n",
      "epoch: 8, inception score: 1.688\n",
      "epoch: 9, inception score: 1.441\n",
      "epoch: 10, inception score: 1.682\n",
      "epoch: 11, inception score: 1.593\n",
      "epoch: 12, inception score: 1.642\n",
      "epoch: 13, inception score: 1.571\n",
      "epoch: 14, inception score: 1.824\n",
      "epoch: 15, inception score: 1.735\n",
      "epoch: 16, inception score: 1.555\n",
      "epoch: 17, inception score: 1.598\n",
      "epoch: 18, inception score: 1.734\n",
      "epoch: 19, inception score: 1.644\n",
      "epoch: 20, inception score: 1.667\n",
      "epoch: 21, inception score: 1.635\n",
      "epoch: 22, inception score: 1.72\n",
      "epoch: 23, inception score: 1.691\n",
      "epoch: 24, inception score: 1.795\n",
      "epoch: 25, inception score: 1.607\n",
      "epoch: 26, inception score: 1.545\n",
      "epoch: 27, inception score: 1.679\n",
      "epoch: 28, inception score: 1.72\n",
      "epoch: 29, inception score: 1.689\n",
      "epoch: 30, inception score: 1.645\n",
      "epoch: 31, inception score: 1.552\n",
      "epoch: 32, inception score: 1.494\n",
      "epoch: 33, inception score: 1.691\n",
      "epoch: 34, inception score: 1.564\n",
      "epoch: 35, inception score: 1.582\n",
      "epoch: 36, inception score: 1.577\n",
      "epoch: 37, inception score: 1.47\n",
      "epoch: 38, inception score: 1.498\n",
      "epoch: 39, inception score: 1.561\n",
      "epoch: 40, inception score: 1.925\n",
      "epoch: 41, inception score: 1.678\n",
      "epoch: 42, inception score: 1.57\n",
      "epoch: 43, inception score: 1.616\n",
      "epoch: 44, inception score: 1.591\n",
      "epoch: 45, inception score: 1.533\n",
      "epoch: 46, inception score: 1.628\n",
      "epoch: 47, inception score: 1.493\n",
      "epoch: 48, inception score: 1.417\n",
      "epoch: 49, inception score: 1.426\n"
     ]
    }
   ],
   "source": [
    "# train WGAN\n",
    "print(\"TRAINING WGAN MODEL...\")\n",
    "train(wgan_generator, wgan_discriminator, train_dataloader)\n",
    "\n",
    "# save WGAN to file\n",
    "torch.save(wgan_generator.state_dict(), 'WGAN_generator.pkl')\n",
    "torch.save(wgan_discriminator.state_dict(), 'WGAN_discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "111ac574-9fea-4590-a5b3-2baf0b6619a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load generator and discriminator model from model file\n",
    "wgan_generator.load_state_dict(torch.load('WGAN_generator.pkl'))\n",
    "wgan_discriminator.load_state_dict(torch.load('WGAN_discriminator.pkl'))\n",
    "\n",
    "#Get 10 samples\n",
    "z = Variable(torch.cuda.FloatTensor(np.random.normal(0, 1, (batch_size, 100))))\n",
    "samples = wgan_generator(z)\n",
    "samples = samples[:10]\n",
    "samples = samples.add(1.0).mul(0.5)\n",
    "samples = samples.data.cpu()\n",
    "\n",
    "#Save 10 samples as immage in 2X10 grid\n",
    "grid = utils.make_grid(samples, nrow=5)\n",
    "utils.save_image(grid, 'wgan_generated_images.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8164233f-fa80-4658-902f-983d1e775e5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
