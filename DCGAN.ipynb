{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4225c827-fa0c-4036-9dcd-7c4e2c050d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import utils\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from pytorch_gan_metrics import get_inception_score\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ba23c00-7005-409b-a61d-6d493213ddc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading CIFAR10 dataset...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "def create_CIFAR10_dataloaders(batch_size): \n",
    "    transform = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor(), \n",
    "        torchvision.transforms.Resize(32), \n",
    "        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "    train_CIFAR10_set = torchvision.datasets.CIFAR10(root='./cifar10/', train=True, download=True, transform=transform)\n",
    "    test_CIFAR10_set = torchvision.datasets.CIFAR10(root='./cifar10/', train=False, download=True, transform=transform)\n",
    "\n",
    "    train_CIFAR10_dataloader = DataLoader(train_CIFAR10_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_CIFAR10_dataloader = DataLoader(test_CIFAR10_set, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    return train_CIFAR10_dataloader, test_CIFAR10_dataloader\n",
    "\n",
    "print(\"Downloading CIFAR10 dataset...\")\n",
    "batch_size = 32\n",
    "train_dataloader, test_dataloader = create_CIFAR10_dataloaders(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11e21abe-a02e-40c5-9c0c-7b0a1184cc93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing generator and discriminator (DCGAN)...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DCGAN_Discriminator(\n",
       "  (net): Sequential(\n",
       "    (0): Conv2d(3, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(1024, 1, kernel_size=(4, 4), stride=(1, 1))\n",
       "    (9): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DCGAN_Generator(nn.Module):\n",
    "    def __init__(self): \n",
    "        super(DCGAN_Generator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=100, out_channels=1024, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(num_features=1024),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(num_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(in_channels=256, out_channels=3, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class DCGAN_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DCGAN_Discriminator, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=256, kernel_size=4, stride=2, padding=1),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(in_channels=256, out_channels=512, kernel_size=4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=4, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(1024),\n",
    "        nn.LeakyReLU(0.2, inplace=True),\n",
    "        nn.Conv2d(in_channels=1024, out_channels=1, kernel_size=4, stride=1, padding=0),\n",
    "        nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "print(\"Initializing generator and discriminator (DCGAN)...\")\n",
    "dcgan_generator = DCGAN_Generator()\n",
    "dcgan_discriminator = DCGAN_Discriminator()\n",
    "dcgan_generator.to(device)\n",
    "dcgan_discriminator.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a6a9b3-4761-4f0c-b36f-d4ace82bb1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0002\n",
    "epochs = 50\n",
    "\n",
    "\n",
    "def train(generator, discriminator, train_dataloader):\n",
    "    loss = nn.BCELoss()  #Binary cross entropy loss\n",
    "    optim_generator = torch.optim.Adam(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "    optim_discriminator = torch.optim.Adam(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "    if not os.path.exists('train_generated_images_dcgan/'): \n",
    "        os.makedirs('train_generated_images_dcgan')\n",
    "        \n",
    "    inception_score_file = open(\"IS_dcgan.csv\", \"w\")\n",
    "    inception_score_file.write('epoch, IS \\n')\n",
    "\n",
    "    for epoch in range(epochs): \n",
    "        for real_images, _ in train_dataloader:\n",
    "            real_images = real_images.to(device)\n",
    "            z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n",
    "            real_labels = torch.ones(batch_size).to(device)\n",
    "            fake_labels = torch.zeros(batch_size).to(device)\n",
    "\n",
    "            ### train discriminator\n",
    "            # compute loss using real images\n",
    "            preds = discriminator(real_images)\n",
    "            disc_loss_real = loss(preds.flatten(), real_labels)\n",
    "\n",
    "            # compute loss using fake images\n",
    "            fake_images = generator(z)\n",
    "            preds = discriminator(fake_images)\n",
    "            disc_loss_fake = loss(preds.flatten(), fake_labels)\n",
    "\n",
    "            # optimize discriminator\n",
    "            disc_loss = disc_loss_real + disc_loss_fake\n",
    "            discriminator.zero_grad()\n",
    "            disc_loss.backward()\n",
    "            optim_discriminator.step()\n",
    "            \n",
    "            ### train generator\n",
    "            # compute loss with fake images\n",
    "            z = Variable(torch.randn(batch_size, 100, 1, 1)).to(device)\n",
    "            fake_images = generator(z)\n",
    "            preds = discriminator(fake_images)\n",
    "            gen_loss = loss(preds.flatten(), real_labels)\n",
    "\n",
    "            # optimize generator \n",
    "            generator.zero_grad()\n",
    "            gen_loss.backward()\n",
    "            optim_generator.step()\n",
    "\n",
    "        # compute inception score and samples every epoch\n",
    "        z = Variable(torch.randn(800, 100, 1, 1)).to(device)\n",
    "        samples = generator(z)\n",
    "\n",
    "        # normalize to [0, 1]\n",
    "        samples = samples.add(1.0).mul(0.5)\n",
    "        \n",
    "        assert 0 <= samples.min() and samples.max() <= 1\n",
    "        IS, IS_std = get_inception_score(samples)\n",
    "        print(\"epoch: \" + str(epoch) + ', inception score: ' + str(round(IS, 3)))\n",
    "\n",
    "        # samples = samples[:10].data.cpu()\n",
    "        # grid = utils.make_grid(samples, nrow = 5)\n",
    "        # utils.save_image(grid, 'train_generated_images_dcgan/epoch_{}.png'.format(str(epoch)))\n",
    "        \n",
    "        inception_score_file.write(str(epoch) + ', ' + str(round(IS, 3)) + '\\n')\n",
    "\n",
    "    inception_score_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2e1aefa-26cb-4f04-9434-a8042bf3392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DCGAN MODEL...\n",
      "epoch: 0, inception score: 2.718\n",
      "epoch: 1, inception score: 2.639\n",
      "epoch: 2, inception score: 3.146\n",
      "epoch: 3, inception score: 3.529\n",
      "epoch: 4, inception score: 3.566\n",
      "epoch: 5, inception score: 3.555\n",
      "epoch: 6, inception score: 3.965\n",
      "epoch: 7, inception score: 3.906\n",
      "epoch: 8, inception score: 4.132\n",
      "epoch: 9, inception score: 4.415\n",
      "epoch: 10, inception score: 4.715\n",
      "epoch: 11, inception score: 4.889\n",
      "epoch: 12, inception score: 4.712\n",
      "epoch: 13, inception score: 4.864\n",
      "epoch: 14, inception score: 4.952\n",
      "epoch: 15, inception score: 4.851\n",
      "epoch: 16, inception score: 4.719\n",
      "epoch: 17, inception score: 5.065\n",
      "epoch: 18, inception score: 4.985\n",
      "epoch: 19, inception score: 4.858\n",
      "epoch: 20, inception score: 4.834\n",
      "epoch: 21, inception score: 5.029\n",
      "epoch: 22, inception score: 5.142\n",
      "epoch: 23, inception score: 4.842\n",
      "epoch: 24, inception score: 5.21\n",
      "epoch: 25, inception score: 5.063\n",
      "epoch: 26, inception score: 5.168\n",
      "epoch: 27, inception score: 5.07\n",
      "epoch: 28, inception score: 5.046\n",
      "epoch: 29, inception score: 5.107\n",
      "epoch: 30, inception score: 5.13\n",
      "epoch: 31, inception score: 5.073\n",
      "epoch: 32, inception score: 5.212\n",
      "epoch: 33, inception score: 5.249\n",
      "epoch: 34, inception score: 5.265\n",
      "epoch: 35, inception score: 5.375\n",
      "epoch: 36, inception score: 5.152\n",
      "epoch: 37, inception score: 5.149\n",
      "epoch: 38, inception score: 5.274\n",
      "epoch: 39, inception score: 5.566\n",
      "epoch: 40, inception score: 5.46\n",
      "epoch: 41, inception score: 5.3\n",
      "epoch: 42, inception score: 5.417\n",
      "epoch: 43, inception score: 5.172\n",
      "epoch: 44, inception score: 5.155\n",
      "epoch: 45, inception score: 5.272\n",
      "epoch: 46, inception score: 5.266\n",
      "epoch: 47, inception score: 5.519\n",
      "epoch: 48, inception score: 5.296\n",
      "epoch: 49, inception score: 5.235\n"
     ]
    }
   ],
   "source": [
    "# train DCGAN\n",
    "print(\"TRAINING DCGAN MODEL...\")\n",
    "train(dcgan_generator, dcgan_discriminator, train_dataloader)\n",
    "\n",
    "# save DCGAN to file\n",
    "torch.save(dcgan_generator.state_dict(), 'DCGAN_generator.pkl')\n",
    "torch.save(dcgan_discriminator.state_dict(), 'DCGAN_discriminator.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1e3d1d8-4126-44aa-9ff6-059b062fd791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load generator and discriminator model from model file\n",
    "dcgan_generator.load_state_dict(torch.load('DCGAN_generator.pkl'))\n",
    "dcgan_discriminator.load_state_dict(torch.load('DCGAN_discriminator.pkl'))\n",
    "\n",
    "#Get 10 samples\n",
    "z = torch.randn(batch_size, 100, 1, 1).to(device)\n",
    "samples = dcgan_generator(z)\n",
    "samples = samples[:10]\n",
    "samples = samples.add(1.0).mul(0.5)\n",
    "samples = samples.data.cpu()\n",
    "\n",
    "#Save 10 samples as immage in 2X10 grid\n",
    "grid = utils.make_grid(samples, nrow=5)\n",
    "utils.save_image(grid, 'dcgan_generated_images.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76ccdd7-6db0-4d5e-8c57-b99b19d4af76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
